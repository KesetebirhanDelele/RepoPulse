RepoPulse — Multi-Repo Progress Scoreboard (Public GitHub, Read-Only)

You are a senior Python engineer + systems architect. Help me build RepoPulse, a local-first Python app that tracks daily/weekly progress across ~30 public GitHub repos (one per developer) where I only have read access. RepoPulse must generate a dashboard and CSV exports that summarize progress, flag risks (docs/CI gaps, churn risk), and help me decide which repos need deep-dive review (download locally).

NEW REQUIREMENT (CRITICAL): Repo signals are first-class inputs

RepoPulse must treat signals (commits, CI status, tags/releases, docs presence, README status block) as first-class inputs.

Signal definitions and scoring rules MUST be external config files under configs/ (YAML/JSON).

No hardcoding of scoring thresholds or required-file lists in code.

CLI MUST support overriding config paths at runtime.

CONTEXT / GOALS

Each developer has their own public repo (not a shared repo).

I need a daily progress snapshot and a weekly scoreboard to run an “architecture & delivery” weekly call.

I will do deep dives by downloading repos locally (shallow clone or zip), but RepoPulse must work even without local clones.

RepoPulse should help answer:

Which repos moved since last check?

Which repos look stuck (no pushes, CI failing, etc.)?

Which repos show churn risk (activity without deliverable signals)?

Which repos lack minimum architecture hygiene (missing docs pack, CI)?

What’s the 1–2 line “what changed” summary per repo for the weekly call?

NON-NEGOTIABLE REQUIREMENTS

Read-only GitHub compatible

Must work on public repos with read access only.

Use GitHub API with token for reliability, but must gracefully degrade without token.

Daily snapshots + weekly rollups

RepoPulse runs daily (manual CLI run is fine for MVP).

It stores snapshots and can produce weekly reports (“since last Wednesday”).

Dashboard + CSV export

Local dashboard: simple web UI (FastAPI + HTML or Streamlit).

Export CSV for:

latest daily snapshot

weekly snapshot for meeting

Signals collected per repo (API-only)

Last commit timestamp (freshness)

Commits in last 24h / 7d

Top files changed (from commit details, limited sample)

CI/Actions latest run status (success/failure/none)

Open issues count (if enabled; otherwise “n/a”)

Latest tag/release (if any)

README updated in last 7d (detect by SHA or commit file changes)

Required docs existence (by repo tree scan):

docs/architecture.md

docs/contracts.md

docs/runbook.md

.github/workflows/* (presence indicates CI exists)

Churn risk detection (heuristic)

RepoPulse must compute “churn risk” using configurable rules, e.g.:

high commit count with no tags/releases,

README Status block unchanged,

high ratio of refactor/chore commits,

repeated changes to same few files,

contracts changing frequently without version marker.

Must label this as a risk (not a definitive judgment).

Green/Yellow/Red (RYG) scoring

Configurable thresholds and conditions.

Output must include: status_ryg + explanation fields (why it’s Yellow/Red).

Traceability

Every computed status and risk flag must store “evidence”: the inputs used (counts, timestamps, last CI conclusion, etc.).

Save run metadata for each execution.

Deep-dive support (local download workflow)

RepoPulse should support generating a “deep dive queue” CSV listing Yellow/Red repos, including:

clone URL

suggested focus areas (docs missing, CI failing, contract churn)

RepoPulse does not need to run the deep analysis itself in MVP, but must prepare the queue.

Minimal working MVP runs locally

Works on Windows/macOS/Linux.

SQLite DB for snapshots.

Simple config-driven rules.

ASSUME

GitHub only (no GitLab).

Public repos.

Local laptop execution.

Python 3.11+.

Common libs allowed: httpx/requests, pydantic, typer, sqlite, pandas, jinja2 (if needed), streamlit (if chosen).

DELIVERABLES YOU MUST PRODUCE IN YOUR ANSWER

A) Folder structure proposal including:

configs/ (signal rules + scoring thresholds)

schemas/ (snapshot/report schema)

app/ modules

data/ sqlite db path

exports/ csv outputs

B) CLI design with examples:

repos add --url ... --owner ...

snapshots run --config configs/default.yaml

report weekly --since 2026-02-11 --out exports/weekly.csv

dashboard run

deepdive queue --out exports/deepdive_queue.csv

C) Config formats

A scoring config that defines:

required files list

RYG thresholds

churn risk rules

D) Data schemas (Pydantic or JSON Schema)

RepoSnapshot schema

WeeklyReportRow schema

RunMetadata schema

E) Python code skeleton

app.py (Typer)

github_client.py (API wrapper + rate limit handling)

collector/ (signals: commits, actions, issues, releases, readme, tree scan)

scoring/ (RYG + churn risk)

storage/ (sqlite models + upsert snapshots)

reporting/ (csv export)

dashboard/ (minimal UI)

logging + unit test stubs

F) Acceptance criteria checks

For each repo snapshot:

required fields present (timestamps, counts)

status_ryg computed with explanation

risk_flags computed with evidence

For each run:

run metadata saved (timestamp, config hash, repos processed count, failures list)

csv files written successfully

OUTPUT RULES

Do NOT ask clarifying questions.

Give copy-pastable code blocks and file contents.

If long, show representative files fully and summarize the rest.

MVP should be runnable without any external services besides GitHub API.

Clearly mark where to plug in optional enhancements (notifications, deeper local analysis).

RUN METADATA

Save run.json per execution including:

run_id

timestamp

repos_processed

failures (repo + error)

config_used path + hash

API mode: token/no-token

scoring version

output paths (csv, db)

NOTES ON “DEVELOPER REPO HYGIENE” (what devs should include)

RepoPulse should detect and report whether each repo has:

Required (minimum)

README “Status” section: milestone, next deliverable date, how to run, known blockers.

Recommended

docs/architecture.md

docs/contracts.md (schemas/APIs/event contracts)

docs/runbook.md

.github/workflows/ci.yml (or equivalent) for CI

RepoPulse must not fail if these are missing; it should mark as risk flags and factor into RYG scoring.

RepoPulse Handoff Prompt (paste into a new window) 02-23-2026

I need you to continue work on my RepoPulse project with full context from the previous session. Here is the situation from the beginning (high level) through the current state:

Project purpose

RepoPulse is a CLI + DB + reporting + web dashboard tool to track multiple GitHub repos (projects), score their “health” (red/yellow/green), surface risk flags, and help leadership focus support on developers/teams.

Environment / workflow rules

We use an in-editor assistant workflow (Claude Code). Changes are made one scoped step at a time.

Repo has CLAUDE.md rules: strict layering (directives/orchestration/execution/tests), tests for non-trivial logic, no secrets in repo, safe scripts, etc.

DB is SQL Server via SQLAlchemy (sqlite allowed but I’m using SQL Server).

.env is used locally (gitignored) to set DB_URL and GITHUB_TOKEN.

What is built (working features)

Packaging/CLI

pip install -e . installs repopulse entrypoint.

CLI supports commands like snapshots, report weekly, deepdive, dashboard, validate configs, db check (when the right CLI is being invoked).

Storage (SQLAlchemy)

Tables: repos, runs, snapshots (snapshots store snapshot_json).

Added schema safety for SQL Server string lengths in sa.py.

Added active column to repos (INTEGER NOT NULL DEFAULT 1).

Added migrate_db() called on startup to ALTER TABLE add active if missing.

Collectors

Commits collector: computes commits_7d/commits_24h and fetches most recent commit when no commits in last 7 days (so last_commit_at isn’t null).

GitHub Actions CI collector (optional via signals.yaml): fetches latest workflow run and normalizes status.

Releases collector: now fetches latest tag and latest GitHub release (enabled via config); unit tested.

Tree/file scan collector: computes hygiene fields:

readme_present

tests_present (real detection via tree scan patterns)

docs_missing (docs/architecture.md, docs/data-model.md, docs/operations.md)

gitignore_present

env_not_tracked (GOOD when .env is not in repo; checked via GitHub contents)

claude_md_present

Important debugging history: claude_md_present initially never appeared because it was missing from Pydantic RepoSnapshot schema and not passed through scoring snapshot creation. Fixed by:

adding field to RepoSnapshot schema

ensuring scoring/engine passes it into RepoSnapshot

ensuring it gets persisted into snapshot_json

Scoring

Produces status_ryg and status_explanation.

Produces risk_flags including:

high_commits_no_release

refactor_heavy

contracts_churn_no_version (but we later planned to make the “no_version” variant only when no tag/release exists).

Reports

weekly.csv generated from latest snapshots since a date.

deepdive queue CSV generated from latest snapshots.

Both now filter out inactive repos (JOIN repos r AND r.active=1).

Dashboard (FastAPI server-rendered HTML)

Portfolio / with filters (status/team), show=active|all, inactive styling, status message banner.

Manage page /manage: multi-repo registration by URL; auto extracts owner/name; optional team; stores in DB; does not edit YAML; shows success banners.

Manage page now includes edit and deactivate/reactivate:

GET /manage/edit (edit team/dev_owner_name/url)

POST /manage/edit

POST /manage/toggle (active flip)

Run snapshots from web: POST /run/snapshots runs in-process pipeline and redirects to portfolio with a message.

Risk heatmap /risks and support page /support exist and are filtered to active repos by default.

Scripts

scripts/run_weekly.ps1 updated:

-Reports generates weekly/deepdive CSVs

-Dashboard starts dashboard

-Since override start date

-BindHost / -BindPort for dashboard (cannot use Host param, reserved).

README/docs updated to include “python -m pytest” and PowerShell script usage.

Testing

pytest scaffolding exists and tests pass (33 tests).

ReleasesCollector tests were updated to handle both cfg dict and signals_path (runtime uses signals_path kwarg).

Release tagging

Tags created and pushed: v0.3.0, v0.3.1, v1.0.0 (tag exists).

A PowerShell script scripts/release.ps1 exists to create tags and GitHub releases via API. It failed to create GitHub releases due to missing/invalid GITHUB_TOKEN in PowerShell env (401 unauthorized). .env token loads in Python but not automatically in PowerShell.